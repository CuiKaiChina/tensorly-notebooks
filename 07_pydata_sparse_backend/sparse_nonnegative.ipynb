{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Non-Negative PARAFAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on [sparse_demo.ipynb](sparse_demo.ipynb#parafac). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we start with a random sparse tensor, constructed so that it has a tensor factorization of rank 5.\n",
    "\n",
    "Because non-negative PARAFAC can take longer to converge than non-masked PARAFAC and also produce dense factors, we will use a smaller tensor than in the other notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<COO: shape=(1000, 5), dtype=float64, nnz=50, fill_value=0.0>,\n",
       " <COO: shape=(1001, 5), dtype=float64, nnz=50, fill_value=0.0>,\n",
       " <COO: shape=(1002, 5), dtype=float64, nnz=50, fill_value=0.0>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (1000, 1001, 1002)\n",
    "rank = 5\n",
    "\n",
    "import sparse\n",
    "starting_weights = sparse.ones(rank)\n",
    "starting_factors = [sparse.random((i, rank)) for i in shape]\n",
    "starting_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><th style=\"text-align: left\">Format</th><td style=\"text-align: left\">coo</td></tr><tr><th style=\"text-align: left\">Data Type</th><td style=\"text-align: left\">float64</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(1000, 1001, 1002)</td></tr><tr><th style=\"text-align: left\">nnz</th><td style=\"text-align: left\">4993</td></tr><tr><th style=\"text-align: left\">Density</th><td style=\"text-align: left\">4.978055876259469e-06</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">True</td></tr><tr><th style=\"text-align: left\">Size</th><td style=\"text-align: left\">156.0K</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">0.0</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<COO: shape=(1000, 1001, 1002), dtype=float64, nnz=4993, fill_value=0.0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorly.contrib.sparse.kruskal_tensor import kruskal_to_tensor\n",
    "tensor = kruskal_to_tensor((starting_weights, starting_factors))\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_size(size_bytes):\n",
    "    size = size_bytes\n",
    "    for unit in ['B', 'KiB', 'MiB', 'GiB', 'TiB']:\n",
    "        if not int(size/1024):\n",
    "            return f'{round(size)}.{unit}'\n",
    "        else:\n",
    "            size /= 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'156.KiB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_size(tensor.nbytes)             # Actual memory usage in GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.0.GiB'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "format_size(np.prod(tensor.shape) * 8)  # Memory usage if array was dense, in GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we factor the tensor. Note that at this time, you have to use the `non_negative_parafac` function from the sparse backend when using a sparse mask to avoid memory blowups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "%load_ext memory_profiler\n",
    "from tensorly.contrib.sparse.decomposition import non_negative_parafac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error=0.8951445796395032\n",
      "iteration 1, reconstraction error: 0.6406660337487468, decrease = 0.25447854589075647\n",
      "iteration 2, reconstraction error: 0.43831537662673414, decrease = 0.2023506571220126\n",
      "iteration 3, reconstraction error: 0.40509622332965045, decrease = 0.03321915329708369\n",
      "iteration 4, reconstraction error: 0.4023990562014931, decrease = 0.002697167128157374\n",
      "iteration 5, reconstraction error: 0.4008966487263428, decrease = 0.0015024074751502914\n",
      "iteration 6, reconstraction error: 0.40005130320432714, decrease = 0.0008453455220156503\n",
      "iteration 7, reconstraction error: 0.39956418126088705, decrease = 0.0004871219434400831\n",
      "iteration 8, reconstraction error: 0.3992726295545541, decrease = 0.0002915517063329376\n",
      "iteration 9, reconstraction error: 0.39908990034777664, decrease = 0.00018272920677747662\n",
      "iteration 10, reconstraction error: 0.39896975652235933, decrease = 0.00012014382541730706\n",
      "iteration 11, reconstraction error: 0.398887163271864, decrease = 8.259325049531085e-05\n",
      "iteration 12, reconstraction error: 0.39882818035130113, decrease = 5.8982920562888896e-05\n",
      "iteration 13, reconstraction error: 0.3987847516142725, decrease = 4.3428737028616826e-05\n",
      "iteration 14, reconstraction error: 0.3987520162294674, decrease = 3.273538480513816e-05\n",
      "iteration 15, reconstraction error: 0.3987269045551158, decrease = 2.511167435159667e-05\n",
      "iteration 16, reconstraction error: 0.39870739002471267, decrease = 1.9514530403108576e-05\n",
      "iteration 17, reconstraction error: 0.3986920796621964, decrease = 1.531036251628537e-05\n",
      "iteration 18, reconstraction error: 0.39867998244092756, decrease = 1.2097221268825287e-05\n",
      "iteration 19, reconstraction error: 0.39867037321726434, decrease = 9.60922366322059e-06\n",
      "iteration 20, reconstraction error: 0.39866270950253646, decrease = 7.663714727879078e-06\n",
      "iteration 21, reconstraction error: 0.39865657842787705, decrease = 6.131074659410096e-06\n",
      "iteration 22, reconstraction error: 0.3986516616046207, decrease = 4.916823256373437e-06\n",
      "iteration 23, reconstraction error: 0.3986477110068529, decrease = 3.950597767754527e-06\n",
      "iteration 24, reconstraction error: 0.39864453190710447, decrease = 3.1790997484515415e-06\n",
      "iteration 25, reconstraction error: 0.3986419704913959, decrease = 2.5614157085906974e-06\n",
      "iteration 26, reconstraction error: 0.3986399046817375, decrease = 2.0658096583914265e-06\n",
      "iteration 27, reconstraction error: 0.39863823722053243, decrease = 1.6674612050571191e-06\n",
      "iteration 28, reconstraction error: 0.3986368903889447, decrease = 1.3468315877562809e-06\n",
      "iteration 29, reconstraction error: 0.39863580192950776, decrease = 1.0884594369153788e-06\n",
      "iteration 30, reconstraction error: 0.398634921871021, decrease = 8.800584867518779e-07\n",
      "PARAFAC converged after 30 iterations\n",
      "Took 0 mins 8 secs\n",
      "peak memory: 151.76 MiB, increment: 18.86 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "start_time = time.time()\n",
    "sparse_kruskal = non_negative_parafac(tensor, rank=rank, init='random', verbose=True)\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print('Took %d mins %d secs' % (divmod(total_time, 60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one of the values that was masked out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39, 14, 11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.coords.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007553350336627013"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_val = tensor[tuple(tensor.coords.T[0])]\n",
    "orig_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [sparse_demo.ipynb](sparse_demo.ipynb) for how to calculate individual values from the factors. Note that we do not compare the entire tensor because it would be dense, and memory usage would be prohibitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007553350336627012"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, factors = sparse_kruskal\n",
    "computed_val = np.sum(np.prod(sparse.stack([factors[i][idx] for i, idx in enumerate(tuple(tensor.coords.T[0]))], 0), 0))\n",
    "computed_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0842021724855044e-19"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(orig_val - computed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f.density for f in factors]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
