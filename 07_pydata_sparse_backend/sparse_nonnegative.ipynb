{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Non-Negative PARAFAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on [sparse_demo.ipynb](sparse_demo.ipynb#parafac). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we start with a random sparse tensor, constructed so that it has a tensor factorization of rank 5.\n",
    "\n",
    "Because non-negative PARAFAC can take longer to converge than non-masked PARAFAC and also produce dense factors, we will use a smaller tensor than in the other notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<COO: shape=(1000, 5), dtype=float64, nnz=50, fill_value=0.0>,\n",
       " <COO: shape=(1001, 5), dtype=float64, nnz=50, fill_value=0.0>,\n",
       " <COO: shape=(1002, 5), dtype=float64, nnz=50, fill_value=0.0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (1000, 1001, 1002)\n",
    "rank = 5\n",
    "\n",
    "import sparse\n",
    "starting_weights = sparse.ones(rank)\n",
    "starting_factors = [sparse.random((i, rank)) for i in shape]\n",
    "starting_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><th style=\"text-align: left\">Format</th><td style=\"text-align: left\">coo</td></tr><tr><th style=\"text-align: left\">Data Type</th><td style=\"text-align: left\">float64</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(1000, 1001, 1002)</td></tr><tr><th style=\"text-align: left\">nnz</th><td style=\"text-align: left\">5091</td></tr><tr><th style=\"text-align: left\">Density</th><td style=\"text-align: left\">5.075762560792501e-06</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">True</td></tr><tr><th style=\"text-align: left\">Size</th><td style=\"text-align: left\">159.1K</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">0.0</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<COO: shape=(1000, 1001, 1002), dtype=float64, nnz=5091, fill_value=0.0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorly.contrib.sparse.kruskal_tensor import kruskal_to_tensor\n",
    "tensor = kruskal_to_tensor((starting_weights, starting_factors))\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000162912"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.nbytes / 1e9                # Actual memory usage in GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.024016"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.prod(tensor.shape) * 8 / 1e9    # Memory usage if array was dense, in GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we factor the tensor. Note that at this time, you have to use the `non_negative_parafac` function from the sparse backend when using a sparse mask to avoid memory blowups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "%load_ext memory_profiler\n",
    "from tensorly.contrib.sparse.decomposition import non_negative_parafac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error=0.9160916858980143\n",
      "iteration 1, reconstraction error: 0.7563893341901149, decrease = 0.15970235170789937\n",
      "iteration 2, reconstraction error: 0.7238710798828315, decrease = 0.03251825430728339\n",
      "iteration 3, reconstraction error: 0.638136189700943, decrease = 0.08573489018188851\n",
      "iteration 4, reconstraction error: 0.6237710805095488, decrease = 0.01436510919139422\n",
      "iteration 5, reconstraction error: 0.6230289529902983, decrease = 0.0007421275192505128\n",
      "iteration 6, reconstraction error: 0.6225200750934725, decrease = 0.0005088778968257435\n",
      "iteration 7, reconstraction error: 0.6221525910453113, decrease = 0.00036748404816122626\n",
      "iteration 8, reconstraction error: 0.6218784625314465, decrease = 0.00027412851386476866\n",
      "iteration 9, reconstraction error: 0.6216689973699929, decrease = 0.0002094651614535925\n",
      "iteration 10, reconstraction error: 0.6215059333127146, decrease = 0.00016306405727828377\n",
      "iteration 11, reconstraction error: 0.6213770599793786, decrease = 0.00012887333333599926\n",
      "iteration 12, reconstraction error: 0.6212738956789091, decrease = 0.00010316430046952707\n",
      "iteration 13, reconstraction error: 0.6211903719957839, decrease = 8.352368312525282e-05\n",
      "iteration 14, reconstraction error: 0.6211220466533541, decrease = 6.832534242973143e-05\n",
      "iteration 15, reconstraction error: 0.6210656095030876, decrease = 5.6437150266486213e-05\n",
      "iteration 16, reconstraction error: 0.6210185594702059, decrease = 4.705003288174581e-05\n",
      "iteration 17, reconstraction error: 0.6209789857524362, decrease = 3.9573717769747496e-05\n",
      "iteration 18, reconstraction error: 0.6209454152097312, decrease = 3.3570542704919326e-05\n",
      "iteration 19, reconstraction error: 0.6209167033291735, decrease = 2.8711880557752423e-05\n",
      "iteration 20, reconstraction error: 0.6208919548075797, decrease = 2.4748521593731532e-05\n",
      "iteration 21, reconstraction error: 0.6208704648241854, decrease = 2.1489983394351597e-05\n",
      "iteration 22, reconstraction error: 0.6208516750998918, decrease = 1.8789724293588606e-05\n",
      "iteration 23, reconstraction error: 0.6208351407199639, decrease = 1.6534379927879428e-05\n",
      "iteration 24, reconstraction error: 0.6208205049055777, decrease = 1.46358143862102e-05\n",
      "iteration 25, reconstraction error: 0.6208074797212468, decrease = 1.3025184330883732e-05\n",
      "iteration 26, reconstraction error: 0.6207958312526106, decrease = 1.1648468636216158e-05\n",
      "iteration 27, reconstraction error: 0.6207853681727001, decrease = 1.046307991048323e-05\n",
      "iteration 28, reconstraction error: 0.6207759328894888, decrease = 9.435283211289835e-06\n",
      "iteration 29, reconstraction error: 0.6207673946677071, decrease = 8.53822178170649e-06\n",
      "iteration 30, reconstraction error: 0.6207596442656972, decrease = 7.750402009953916e-06\n",
      "iteration 31, reconstraction error: 0.6207525897383988, decrease = 7.054527298433477e-06\n",
      "iteration 32, reconstraction error: 0.6207461531404168, decrease = 6.436597981940295e-06\n",
      "iteration 33, reconstraction error: 0.6207402679257922, decrease = 5.885214624634649e-06\n",
      "iteration 34, reconstraction error: 0.6207348768885662, decrease = 5.391037225965789e-06\n",
      "iteration 35, reconstraction error: 0.620729930524411, decrease = 4.946364155156147e-06\n",
      "iteration 36, reconstraction error: 0.6207253857211406, decrease = 4.544803270500886e-06\n",
      "iteration 37, reconstraction error: 0.620721204706963, decrease = 4.181014177540021e-06\n",
      "iteration 38, reconstraction error: 0.6207173542014605, decrease = 3.850505502556167e-06\n",
      "iteration 39, reconstraction error: 0.620713804726611, decrease = 3.549474849484646e-06\n",
      "iteration 40, reconstraction error: 0.6207105300446585, decrease = 3.274681952492031e-06\n",
      "iteration 41, reconstraction error: 0.6207075066969373, decrease = 3.023347721176073e-06\n",
      "iteration 42, reconstraction error: 0.6207047136233642, decrease = 2.7930735730929968e-06\n",
      "iteration 43, reconstraction error: 0.6207021318466902, decrease = 2.581776674004388e-06\n",
      "iteration 44, reconstraction error: 0.6206997442089445, decrease = 2.387637745737692e-06\n",
      "iteration 45, reconstraction error: 0.6206975351501464, decrease = 2.2090587981082876e-06\n",
      "iteration 46, reconstraction error: 0.6206954905214015, decrease = 2.0446287448683265e-06\n",
      "iteration 47, reconstraction error: 0.6206935974260861, decrease = 1.8930953153972752e-06\n",
      "iteration 48, reconstraction error: 0.6206918440840994, decrease = 1.7533419867099553e-06\n",
      "iteration 49, reconstraction error: 0.6206902197151348, decrease = 1.6243689645589754e-06\n",
      "iteration 50, reconstraction error: 0.6206887144377234, decrease = 1.505277411384398e-06\n",
      "iteration 51, reconstraction error: 0.6206873191814032, decrease = 1.3952563202579427e-06\n",
      "iteration 52, reconstraction error: 0.6206860256098873, decrease = 1.29357151590348e-06\n",
      "iteration 53, reconstraction error: 0.6206848260534784, decrease = 1.1995564088707056e-06\n",
      "iteration 54, reconstraction error: 0.6206837134493074, decrease = 1.1126041710163292e-06\n",
      "iteration 55, reconstraction error: 0.620682681288232, decrease = 1.0321610753871724e-06\n",
      "iteration 56, reconstraction error: 0.6206817235674227, decrease = 9.577208093247691e-07\n",
      "PARAFAC converged after 56 iterations\n",
      "Took 0 mins 9 secs\n",
      "peak memory: 118.69 MiB, increment: 3.73 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "start_time = time.time()\n",
    "sparse_kruskal = non_negative_parafac(tensor, rank=rank, init='random', verbose=True)\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print('Took %d mins %d secs' % (divmod(total_time, 60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one of the values that was masked out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 18, 116,  45])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.coords.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5859621618332147"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_val = tensor[tuple(tensor.coords.T[0])]\n",
    "orig_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [sparse_demo.ipynb](sparse_demo.ipynb) for how to calculate individual values from the factors. Note that we do not compare the entire tensor because it would be dense, and memory usage would be prohibitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2044092111848095e-32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, factors = sparse_kruskal\n",
    "computed_val = np.sum(np.prod(sparse.stack([factors[i][idx] for i, idx in enumerate(tuple(tensor.coords.T[0]))], 0), 0))\n",
    "computed_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5859621618332147"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(orig_val - computed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f.density for f in factors]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
